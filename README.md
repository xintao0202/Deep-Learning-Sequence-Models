# Deep-Learning-Sequence-Models
Coursera Course
Course Webiste https://www.coursera.org/learn/nlp-sequence-models/home/welcome

1.1 Sampling novel sequences in RNN
- Use the probabilities output by the RNN to randomly sample a chosen word for that time-step as y^(t), Then pass this selected word to the next time-step

1.2 Gated Recurrent Unit (GRU)
-  when Gamma_u =0 (gate=0), C<t> is only dependent on C<t-1>, means don't update, thus it doesn't suffer from much of a vanishing gradient problem

1.3 Logistic Regression with a Neural Network mindset project
  - [Building_a_Recurrent_Neural_Network_Step_by_Step Link](Building_a_Recurrent_Neural_Network_Step_by_Step_v3a.ipynb)

1.4 Dinosaurus Land Character Level Language Model Project
 - [Dinosaurus Land Character Level Language Model](Dinosaurus_Island_Character_level_language_model_final_v3a.ipynb)
 
1.5 Improvise a Jazz Solo with an LSTM Network Project
 - [Improvise_a_Jazz_Solo_with_an_LSTM_Network](Improvise_a_Jazz_Solo_with_an_LSTM_Network_v3a.ipynb)
 - [Generated Musci] (my_music.midi)
